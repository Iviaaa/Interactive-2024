
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="style.css">
    <title>Zivyskidski</title>
    <link rel="icon" type="image/png" href="images/favcon.png" />
    <!--LINK JQUERY-->
    <script type="text/javascript" src="jquery-3.7.1.min.js"></script>
</head>

<body>
    <div class="description" style="position: fixed; top:15vh; width: 20vw; font-size: 96px; z-index: 1;color: red;">
        <bold>IKHYF (2024)</bold>
    </div>

    <div class="description" style="position: fixed; top:15vh; left: 83vw; width: 15vw ;z-index: 1;font-size: 18px">
            Utilizing the API provided by ChatGPT in TouchDesigner, <span style="color:red">IKHYF(I know how you feel)</span> listens to the voice input from an audience, analyzes the emotion undertone, and output an animated design.
            <br><br>What are we not noticing when we speak? To what extent does  AI understand human emotions? And when we interact with the machine, what psychological progress do we experience? The project aims to not only help designers see the color in their voice, but also evoke a reflection on the continuity between human and machine.
        </div>
<div id="videobox" style="z-index: -1;"> 
    <iframe width="1120" height="630"  src="https://www.youtube.com/embed/qbs-YQhKb-4?si=T7x2a3n72LPu34zm">
    </iframe>
    </div>
</body>

</html>